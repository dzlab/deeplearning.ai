{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ee333b4-4b2e-4e45-8833-3a6e4782b46c",
   "metadata": {},
   "source": [
    "# Pair Programming Scenarios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279e9386-c8cd-4825-afcc-43e3191cad69",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "Set the MakerSuite API key with the provided helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa172d-0b5d-4fd1-9051-3d6f2e31730f",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import get_api_key\n",
    "import google.generativeai as palm\n",
    "from google.api_core import client_options as client_options_lib\n",
    "\n",
    "palm.configure(\n",
    "    api_key=get_api_key(),\n",
    "    transport=\"rest\",\n",
    "    client_options=client_options_lib.ClientOptions(\n",
    "        api_endpoint=os.getenv(\"GOOGLE_API_BASE\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18775c71-13f5-49ff-ac4a-d34cb33afb0a",
   "metadata": {},
   "source": [
    "#### Pick the model that generates text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ff7acb-6793-49b1-bf59-993c1a3bd612",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "model_bison = models[0]\n",
    "model_bison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6efbc6-7f98-4760-9ac0-3b513ef47d6a",
   "metadata": {},
   "source": [
    "#### Helper function to call the PaLM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008d0c81-4a13-42e2-b0e3-5fe65c56fc18",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "@retry.Retry()\n",
    "def generate_text(prompt, \n",
    "                  model=model_bison, \n",
    "                  temperature=0.0):\n",
    "    return palm.generate_text(prompt=prompt,\n",
    "                              model=model,\n",
    "                              temperature=temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d25195-6e75-4617-a70c-f5486f9300bb",
   "metadata": {},
   "source": [
    "### Scenario 1: Improve existing code\n",
    "- An LLM can help you rewrite your code in the way that's recommended for that particular language.\n",
    "- You can ask an LLM to rewrite your Python code in a way that is more 'Pythonic\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d76836a-7e57-4858-8ae5-0e2b6f6ae682",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "I don't think this code is the best way to do it in Python, can you help me?\n",
    "\n",
    "{question}\n",
    "\n",
    "Please explain, in detail, what you did to improve it.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d292a-4c66-4fe0-94f9-09de640f075e",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "def func_x(array)\n",
    "  for i in range(len(array)):\n",
    "    print(array[i])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4944ff9-93c2-4a61-9ac0-54bff53d6ad4",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "completion = generate_text(\n",
    "    prompt = prompt_template.format(question=question)\n",
    ")\n",
    "print(completion.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b702c38c-a6ea-4eb2-978b-caf67e79c869",
   "metadata": {},
   "source": [
    "#### Ask for multiple ways of rewriting your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3cfe0b-2ec5-452a-bee6-ceb14cbd3f0a",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "I don't think this code is the best way to do it in Python, can you help me?\n",
    "\n",
    "{question}\n",
    "\n",
    "Please explore multiple ways of solving the problem, and explain each.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b598a-ff33-48f0-b58a-e1a355897a56",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "completion = generate_text(\n",
    "    prompt = prompt_template.format(question=question)\n",
    ")\n",
    "print(completion.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eee86fb-5c10-4e49-a830-7fbe56de241a",
   "metadata": {},
   "source": [
    "#### Paste markdown into a markdown cell\n",
    "\n",
    "If the model outputs what looks like a table in markdown, you can copy-paste markdown into a markdown cell to make it easier to view:\n",
    "\n",
    "For example:\n",
    "\n",
    "| Method | Pros | Cons |\n",
    "|---|---|---|\n",
    "| List comprehension | Concise | Can be difficult to read for complex code |\n",
    "| `enumerate()` | Easy to read | Requires an extra variable to store the index |\n",
    "| `map()` | Flexible | Requires a custom function to format the output |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df910404-db59-4b9e-9477-408ccec9b7fc",
   "metadata": {},
   "source": [
    "#### Ask the model to recommend one of the methods as most 'Pythonic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b776a8cb-80c4-4e20-89dc-7bff2a350b9a",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "I don't think this code is the best way to do it in Python, can you help me?\n",
    "\n",
    "{question}\n",
    "\n",
    "Please explore multiple ways of solving the problem, \n",
    "and tell me which is the most Pythonic\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89521d8c-41c8-45fd-9ec3-5eea54c642a4",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "completion = generate_text(\n",
    "    prompt = prompt_template.format(question=question)\n",
    ")\n",
    "print(completion.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47315eff-85d3-45aa-bf14-a6f8ee1a43b9",
   "metadata": {},
   "source": [
    "### Scenario 2: Simplify code\n",
    "- Ask the LLM to perform a code review.\n",
    "- Note that adding/removing newline characters may affect the LLM completion that gets output by the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b24b6-c20c-4e3b-9f80-1a6dea18fa24",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# option 1\n",
    "prompt_template = \"\"\"\n",
    "Can you please simplify this code for a linked list in Python?\n",
    "\n",
    "{question}\n",
    "\n",
    "Explain in detail what you did to modify it, and why.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c075dc-2f21-4ab5-99ed-798c08d20bad",
   "metadata": {},
   "source": [
    "After you try option 1, you can modify it to look like option 2 (in this markdown cell) and see how it changes the completion.\n",
    "```Python\n",
    "# option 2\n",
    "prompt_template = \"\"\"\n",
    "Can you please simplify this code for a linked list in Python? \\n\n",
    "You are an expert in Pythonic code.\n",
    "\n",
    "{question}\n",
    "\n",
    "Please comment each line in detail, \\n\n",
    "and explain in detail what you did to modify it, and why.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4663db7e-3b40-4776-9dc9-87fea5975ff1",
   "metadata": {
    "height": 319
   },
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "class Node:\n",
    "  def __init__(self, dataval=None):\n",
    "    self.dataval = dataval\n",
    "    self.nextval = None\n",
    "\n",
    "class SLinkedList:\n",
    "  def __init__(self):\n",
    "    self.headval = None\n",
    "\n",
    "list1 = SLinkedList()\n",
    "list1.headval = Node(\"Mon\")\n",
    "e2 = Node(\"Tue\")\n",
    "e3 = Node(\"Wed\")\n",
    "list1.headval.nextval = e2\n",
    "e2.nextval = e3\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f954dcaf-3dfe-4265-b644-1bcbeead405b",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "completion = generate_text(\n",
    "    prompt = prompt_template.format(question=question)\n",
    ")\n",
    "print(completion.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2842f412-36f7-461f-a07f-eb95b345174d",
   "metadata": {},
   "source": [
    "### Scenario 3: Write test cases\n",
    "\n",
    "- It may help to specify that you want the LLM to output \"in code\" to encourage it to write unit tests instead of just returning test cases in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c29c6-fe80-4aed-9e86-2daa6d862101",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Can you please create test cases in code for this Python code?\n",
    "\n",
    "{question}\n",
    "\n",
    "Explain in detail what these test cases are designed to achieve.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3259b810-52b4-446b-971b-136df45d0f97",
   "metadata": {
    "height": 387
   },
   "outputs": [],
   "source": [
    "# Note that the code I'm using here was output in the previous\n",
    "# section. Your output code may be different.\n",
    "question = \"\"\"\n",
    "class Node:\n",
    "  def __init__(self, dataval=None):\n",
    "    self.dataval = dataval\n",
    "    self.nextval = None\n",
    "\n",
    "class SLinkedList:\n",
    "  def __init__(self):\n",
    "    self.head = None\n",
    "\n",
    "def create_linked_list(data):\n",
    "  head = Node(data[0])\n",
    "  for i in range(1, len(data)):\n",
    "    node = Node(data[i])\n",
    "    node.nextval = head\n",
    "    head = node\n",
    "  return head\n",
    "\n",
    "list1 = create_linked_list([\"Mon\", \"Tue\", \"Wed\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab46dc7e-393a-4ec3-a443-39b39437dd05",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "completion = generate_text(\n",
    "    prompt = prompt_template.format(question=question)\n",
    ")\n",
    "print(completion.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e34dd-167c-4ce5-b0a6-20b1cf78f53c",
   "metadata": {},
   "source": [
    "### Scenario 4: Make code more efficient\n",
    "- Improve runtime by potentially avoiding inefficient methods (such as ones that use recursion when not needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4197f9-c6de-490d-a05e-6b604e0c0c40",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Can you please make this code more efficient?\n",
    "\n",
    "{question}\n",
    "\n",
    "Explain in detail what you changed and why.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f653f4e0-c847-4639-8702-a9b16b161c24",
   "metadata": {
    "height": 489
   },
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "# Returns index of x in arr if present, else -1\n",
    "def binary_search(arr, low, high, x):\n",
    "    # Check base case\n",
    "    if high >= low:\n",
    "        mid = (high + low) // 2\n",
    "        if arr[mid] == x:\n",
    "            return mid\n",
    "        elif arr[mid] > x:\n",
    "            return binary_search(arr, low, mid - 1, x)\n",
    "        else:\n",
    "            return binary_search(arr, mid + 1, high, x)\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "# Test array\n",
    "arr = [ 2, 3, 4, 10, 40 ]\n",
    "x = 10\n",
    "\n",
    "# Function call\n",
    "result = binary_search(arr, 0, len(arr)-1, x)\n",
    "\n",
    "if result != -1:\n",
    "    print(\"Element is present at index\", str(result))\n",
    "else:\n",
    "    print(\"Element is not present in array\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0150e46-ca82-420d-82ec-54eca96bd3d2",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "completion = generate_text(\n",
    "    prompt = prompt_template.format(question=question)\n",
    ")\n",
    "print(completion.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a24541-c37b-48a0-bc71-a8323f0b9e2d",
   "metadata": {},
   "source": [
    "#### Try out the LLM-generated code\n",
    "- If it uses `bisect`, you may first need to `import bisect`\n",
    "- Remember to check what the generated code is actually doing.  For instance, the code may work because it is calling a predefined function (such as `bisect`), even though the rest of the code is technically broken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecde2b81-6e00-4977-b888-39e2f65a8d79",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# Paste the LLM-generated code to inspect and debug it\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7326a0cc-338b-4c83-9b57-3a84094f800a",
   "metadata": {},
   "source": [
    "### Scenario 5: Debug your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10179f2-e09e-4c72-9991-a6f5d8418fc4",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Can you please help me to debug this code?\n",
    "\n",
    "{question}\n",
    "\n",
    "Explain in detail what you found and why it was a bug.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8384ba-3641-407e-add6-52efa2a43b48",
   "metadata": {
    "height": 625
   },
   "outputs": [],
   "source": [
    "# I deliberately introduced a bug into this code! Let's see if the LLM can find it.\n",
    "# Note -- the model can't see this comment -- but the bug is in the\n",
    "# print function. There's a circumstance where nodes can be null, and trying\n",
    "# to print them would give a null error.\n",
    "question = \"\"\"\n",
    "class Node:\n",
    "   def __init__(self, data):\n",
    "      self.data = data\n",
    "      self.next = None\n",
    "      self.prev = None\n",
    "\n",
    "class doubly_linked_list:\n",
    "   def __init__(self):\n",
    "      self.head = None\n",
    "\n",
    "# Adding data elements\n",
    "   def push(self, NewVal):\n",
    "      NewNode = Node(NewVal)\n",
    "      NewNode.next = self.head\n",
    "      if self.head is not None:\n",
    "         self.head.prev = NewNode\n",
    "      self.head = NewNode\n",
    "\n",
    "# Print the Doubly Linked list in order\n",
    "   def listprint(self, node):\n",
    "       print(node.data),\n",
    "       last = node\n",
    "       node = node.next\n",
    "\n",
    "dllist = doubly_linked_list()\n",
    "dllist.push(12)\n",
    "dllist.push(8)\n",
    "dllist.push(62)\n",
    "dllist.listprint(dllist.head)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4874fd-722a-4b3d-8ca1-fab36c5e84f4",
   "metadata": {},
   "source": [
    "Notice in this case that we are using the default temperature of `0.7` to generate the example that you're seeing in the lecture video.  \n",
    "- Since a temperature > 0 encourages more randomness in the LLM output, you may want to run this code a couple times to see what it outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360527f9-495e-41f4-a280-579f3643a36b",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "completion = generate_text(\n",
    "    prompt = prompt_template.format(question=question),\n",
    "    temperature = 0.7\n",
    ")\n",
    "print(completion.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c9d0dc-c216-4ea5-8ccd-1f06094b9fad",
   "metadata": {},
   "source": [
    "#### Reminder to check the code\n",
    "You can use an  LLM to give you insights and check for blind spots, but remember to check that the generated code is doing what you want it to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80634c53-72b8-43ee-8ac0-369fce8c0318",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
