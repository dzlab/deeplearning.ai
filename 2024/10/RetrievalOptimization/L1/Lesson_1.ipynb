{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56bb3b2c-faeb-41ec-8499-508a8bc71b76",
   "metadata": {},
   "source": [
    "# L1: Embedding Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a61c8-d1bc-4c93-b1aa-05c1070fb52d",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a39a02-fc59-4c46-ad00-0691bdf11fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6851df66-ded3-40f2-b252-c680a32921de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6938626-dba6-454f-a150-f560144a14c5",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6ff; padding:15px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\"> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. For more help, please see the <em>\"Appendix - Tips and Help\"</em> Lesson.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd44f86-2aab-46f1-99ec-ea73eac92c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = model.tokenize([\"walker walked a long walk\"])\n",
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74912810-c4ef-4373-86d6-77a095ef01ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tokenizer.convert_ids_to_tokens(tokenized_data[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aced61-6e22-4ebe-bd35-60509e744aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer consists of multiple stack modules. Tokens are an input\n",
    "# of the first one, so we can ignore the rest.\n",
    "first_module = model._first_module()\n",
    "first_module.auto_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d31f2b1-a552-4074-b8f6-baac9a3afed7",
   "metadata": {},
   "source": [
    "## Input token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbdde63-90d6-493c-8316-96869c366a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = first_module.auto_model.embeddings\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e11176-0f9c-40e2-bbe0-fc9da008e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import plotly.express as px\n",
    "\n",
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")  # Use MPS for Apple, CUDA for others, or fallback to CPU\n",
    "\n",
    "first_sentence = \"vector search optimization\"\n",
    "second_sentence = \"we learn to apply vector search optimization\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Tokenize both texts\n",
    "    first_tokens = model.tokenize([first_sentence])\n",
    "    second_tokens = model.tokenize([second_sentence])\n",
    "    \n",
    "    # Get the corresponding embeddings\n",
    "    first_embeddings = embeddings.word_embeddings(\n",
    "        first_tokens[\"input_ids\"].to(device)\n",
    "    )\n",
    "    second_embeddings = embeddings.word_embeddings(\n",
    "        second_tokens[\"input_ids\"].to(device)\n",
    "    )\n",
    "\n",
    "first_embeddings.shape, second_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc85bd-53c6-41b6-8fba-062ba9f82661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "distances = util.cos_sim(\n",
    "    first_embeddings.squeeze(), \n",
    "    second_embeddings.squeeze()\n",
    ").cpu().numpy() # Move the tensor to the CPU and convert to a NumPy array\n",
    "\n",
    "px.imshow(\n",
    "    distances, \n",
    "    x=model.tokenizer.convert_ids_to_tokens(\n",
    "        second_tokens[\"input_ids\"][0]\n",
    "    ),\n",
    "    y=model.tokenizer.convert_ids_to_tokens(\n",
    "        first_tokens[\"input_ids\"][0]\n",
    "    ),\n",
    "    text_auto=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175aa3d9-3daf-46b9-ace7-8a95b3462ffd",
   "metadata": {},
   "source": [
    "### Visualizing the input embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc73f36-ce2c-45d6-b2e6-834e7b7fe24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings = first_module.auto_model \\\n",
    "    .embeddings \\\n",
    "    .word_embeddings \\\n",
    "    .weight \\\n",
    "    .detach() \\\n",
    "    .cpu() \\\n",
    "    .numpy()\n",
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c9f6ec-7612-4fc0-9de5-fe9af772e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "vocabulary = first_module.tokenizer.get_vocab()\n",
    "sorted_vocabulary = sorted(\n",
    "    vocabulary.items(), \n",
    "    key=lambda x: x[1],  # uses the value of the dictionary entry\n",
    ")\n",
    "sorted_tokens = [token for token, _ in sorted_vocabulary]\n",
    "random.choices(sorted_tokens, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fbd3ce-49e3-455d-8a2d-a7a3bd4658cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, metric=\"cosine\", random_state=42)\n",
    "tsne_embeddings_2d = tsne.fit_transform(token_embeddings)\n",
    "tsne_embeddings_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb4b03d-a3b8-4456-9615-3e4bf86ed19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_colors = []\n",
    "for token in sorted_tokens:\n",
    "    if token[0] == \"[\" and token[-1] == \"]\":\n",
    "        token_colors.append(\"red\")\n",
    "    elif token.startswith(\"##\"):\n",
    "        token_colors.append(\"blue\")\n",
    "    else:\n",
    "        token_colors.append(\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e99b0fe-8723-4193-aec4-7af50f4d296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "scatter = go.Scattergl(\n",
    "    x=tsne_embeddings_2d[:, 0], \n",
    "    y=tsne_embeddings_2d[:, 1],\n",
    "    text=sorted_tokens,\n",
    "    marker=dict(color=token_colors, size=3),\n",
    "    mode=\"markers\",\n",
    "    name=\"Token embeddings\",\n",
    ")\n",
    "\n",
    "fig = go.FigureWidget(\n",
    "    data=[scatter],\n",
    "    layout=dict(\n",
    "        width=600,\n",
    "        height=900,\n",
    "        margin=dict(l=0, r=0),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ac92ec-0aa1-4582-8c54-db33f024bc63",
   "metadata": {},
   "source": [
    "## Output token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abca87e-db68-498e-b137-d00a77f034b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_embedding = model.encode([\"walker walked a long walk\"])\n",
    "output_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf5ca5b-3b56-4b17-b647-d91bf0a6b33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_token_embeddings = model.encode(\n",
    "    [\"walker walked a long walk\"], \n",
    "    output_value=\"token_embeddings\"\n",
    ")\n",
    "output_token_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963521e9-bab7-4021-b21a-4775f38c994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sentence = \"vector search optimization\"\n",
    "second_sentence = \"we learn to apply vector search optimization\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    first_tokens = model.tokenize([first_sentence])\n",
    "    second_tokens = model.tokenize([second_sentence])\n",
    "    \n",
    "    first_embeddings = model.encode(\n",
    "        [first_sentence], \n",
    "        output_value=\"token_embeddings\"\n",
    "    )\n",
    "    second_embeddings = model.encode(\n",
    "        [second_sentence], \n",
    "        output_value=\"token_embeddings\"\n",
    "    )\n",
    "\n",
    "distances = util.cos_sim(\n",
    "    first_embeddings[0], \n",
    "    second_embeddings[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7500af15-5de5-498b-b098-6d1554783257",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(\n",
    "    distances.cpu().numpy(),  # Move the tensor to CPU and convert to a NumPy array\n",
    "    x=model.tokenizer.convert_ids_to_tokens(\n",
    "        second_tokens[\"input_ids\"][0]\n",
    "    ),\n",
    "    y=model.tokenizer.convert_ids_to_tokens(\n",
    "        first_tokens[\"input_ids\"][0]\n",
    "    ),\n",
    "    text_auto=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ffe74e-968f-4b37-ab73-5686c18a8af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee843700-b778-4af3-901c-53d420b12f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a62bb-7713-4e88-acb1-621e1da38203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a3e6cc-4787-4922-a0f9-e98ac5eac5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db97e61-b26b-4628-bebd-94290afe3d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687670ec-9c81-4305-bb7e-377de2d50afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cfba8a-6d99-4d12-b786-2a0a5fc9f0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
