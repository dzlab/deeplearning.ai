{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b30f0f5-eb81-4bb5-b8ed-8ed649445113",
   "metadata": {},
   "source": [
    "# L2: Build Customized RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff13202-e13c-43bd-aa5f-a2bafc34e738",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14938a7d-8274-4539-b955-2eed27519bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from helper import load_env\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "load_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaedb67-7c49-499b-afce-b286a5b655c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.utils.auth import Secret\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.converters import HTMLToDocument\n",
    "from haystack.components.fetchers import LinkContentFetcher\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "from haystack_integrations.components.embedders.cohere import CohereDocumentEmbedder, CohereTextEmbedder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2358e62b-a797-4c5f-b803-99408c41de31",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6ff; padding:15px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\"> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. For more help, please see the <em>\"Appendix - Tips and Help\"</em> Lesson.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889dbb29",
   "metadata": {},
   "source": [
    "- Fetch Contents from URLs with [`LinkContentFetcher`](https://docs.haystack.deepset.ai/docs/linkcontentfetcher?utm_campaign=developer-relations&utm_source=dlai)\n",
    "- Convert them to Documents with [`HTMLToDocument`](https://docs.haystack.deepset.ai/docs/htmltodocument?utm_campaign=developer-relations&utm_source=dlai)\n",
    "- Create embeddings for them with [`CohereDocumentEmbedder`](https://docs.haystack.deepset.ai/docs/coheredocumentembedder?utm_campaign=developer-relations&utm_source=dlai)\n",
    "- Write them to an [`InMemoryDocumentStore`](https://docs.haystack.deepset.ai/docs/inmemorydocumentstore?utm_campaign=developer-relations&utm_source=dlai)\n",
    "\n",
    "> ‚ÑπÔ∏è Model providers may have outages. If you encounter issues creating embeddings or generating responses, feel free to consider any of the other [Embedder](https://docs.haystack.deepset.ai/docs/embedders?utm_campaign=developer-relations&utm_source=dlai) or [Generator](https://docs.haystack.deepset.ai/docs/generators?utm_campaign=developer-relations&utm_source=dlai) options. For this lesson, we recomment Cohere embedders, or small [Sentence Transformers](https://docs.haystack.deepset.ai/docs/sentencetransformersdocumentembedder?utm_campaign=developer-relations&utm_source=dlai) embedders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011f2c98-b351-41ed-94a8-af42ed290c39",
   "metadata": {},
   "source": [
    "## Indexing Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a483e863-cd4e-497b-afc4-6934e2f9a409",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "fetcher = LinkContentFetcher()\n",
    "converter = HTMLToDocument()\n",
    "embedder = CohereDocumentEmbedder(model=\"embed-english-v3.0\", api_base_url=os.getenv(\"CO_API_URL\"))\n",
    "writer = DocumentWriter(document_store=document_store)\n",
    "\n",
    "indexing = Pipeline()\n",
    "indexing.add_component(\"fetcher\", fetcher)\n",
    "indexing.add_component(\"converter\", converter)\n",
    "indexing.add_component(\"embedder\", embedder)\n",
    "indexing.add_component(\"writer\", writer)\n",
    "\n",
    "indexing.connect(\"fetcher.streams\", \"converter.sources\")\n",
    "indexing.connect(\"converter\", \"embedder\")\n",
    "indexing.connect(\"embedder\", \"writer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3666b9-5c3e-4b0d-8bac-559ceeeedfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7703884-e87e-4b2d-9218-1489e57c6134",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing.run(\n",
    "    {\n",
    "        \"fetcher\": {\n",
    "            \"urls\": [\n",
    "                \"https://haystack.deepset.ai/integrations/cohere\",\n",
    "                \"https://haystack.deepset.ai/integrations/anthropic\",\n",
    "                \"https://haystack.deepset.ai/integrations/jina\",\n",
    "                \"https://haystack.deepset.ai/integrations/nvidia\",\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c9ac88-6154-4028-a468-6242e0d66731",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.filter_documents()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2767b08f-8eb7-481f-8000-49bd47a5a344",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation\n",
    "### 1. Decide on the Prompt\n",
    "Augment the prompt with the contents of these documents using the [`PromptBuilder`](https://docs.haystack.deepset.ai/docs/promptbuilder?utm_campaign=developer-relations&utm_source=dlai). This component uses Jinja templating [[+]](https://jinja.palletsprojects.com/en/3.1.x/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79dced8-ba37-4675-ab1c-6d996fbceccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Answer the question based on the provided context.\n",
    "Context:\n",
    "{% for doc in documents %}\n",
    "   {{ doc.content }} \n",
    "{% endfor %}\n",
    "Question: {{ query }}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04835441-f434-4e26-9846-ff1e22125e28",
   "metadata": {},
   "source": [
    "### 2. Build the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a421b514-187d-4e6b-814a-be12b89f86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedder = CohereTextEmbedder(model=\"embed-english-v3.0\", api_base_url=os.getenv(\"CO_API_URL\"))\n",
    "retriever = InMemoryEmbeddingRetriever(document_store=document_store)\n",
    "prompt_builder = PromptBuilder(template=prompt)\n",
    "generator = OpenAIGenerator()\n",
    "\n",
    "rag = Pipeline()\n",
    "rag.add_component(\"query_embedder\", query_embedder)\n",
    "rag.add_component(\"retriever\", retriever)\n",
    "rag.add_component(\"prompt\", prompt_builder)\n",
    "rag.add_component(\"generator\", generator)\n",
    "\n",
    "rag.connect(\"query_embedder.embedding\", \"retriever.query_embedding\")\n",
    "rag.connect(\"retriever.documents\", \"prompt.documents\")\n",
    "rag.connect(\"prompt\", \"generator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019dd350",
   "metadata": {},
   "source": [
    "> Note: It is possible to use a different model for the generator. For example, if you'd like to use Llama-3, update the code above to:\n",
    "\n",
    "```\n",
    "generator = OpenAIGenerator(api_key=Secret.from_env_var(\"TOGETHER_AI_API\"),\n",
    "                            model=\"meta-llama/Llama-3-70b-chat-hf\",\n",
    "                            api_base_url=\"https://api.together.xyz/v1\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78311bda-29c3-4182-bf32-31539b044e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1468ab3-674d-45a7-91de-4121f2b2f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How can I use Cohere with Haystack?\"\n",
    "\n",
    "result = rag.run(\n",
    "    {\n",
    "        \"query_embedder\": {\"text\": question},\n",
    "        \"retriever\": {\"top_k\": 1},\n",
    "        \"prompt\": {\"query\": question},\n",
    "    }\n",
    ")\n",
    "\n",
    "print(result[\"generator\"][\"replies\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2ed8d4-7e54-46db-9238-6c69f152c002",
   "metadata": {},
   "source": [
    "### 3. Customize The Behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b99efc-d51f-47d9-b2f3-22f32dc583d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You will be provided some context, followed by the URL that this context comes from.\n",
    "Answer the question based on the context, and reference the URL from which your answer is generated.\n",
    "Your answer should be in {{ language }}.\n",
    "Context:\n",
    "{% for doc in documents %}\n",
    "   {{ doc.content }} \n",
    "   URL: {{ doc.meta['url']}}\n",
    "{% endfor %}\n",
    "Question: {{ query }}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097aecbb-f7b6-4821-a2c4-33f0b06a0373",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedder = CohereTextEmbedder(model=\"embed-english-v3.0\", api_base_url=os.getenv(\"CO_API_URL\"))\n",
    "retriever = InMemoryEmbeddingRetriever(document_store=document_store)\n",
    "prompt_builder = PromptBuilder(template=prompt)\n",
    "generator = OpenAIGenerator(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "rag = Pipeline()\n",
    "rag.add_component(\"query_embedder\", query_embedder)\n",
    "rag.add_component(\"retriever\", retriever)\n",
    "rag.add_component(\"prompt\", prompt_builder)\n",
    "rag.add_component(\"generator\", generator)\n",
    "\n",
    "rag.connect(\"query_embedder.embedding\", \"retriever.query_embedding\")\n",
    "rag.connect(\"retriever.documents\", \"prompt.documents\")\n",
    "rag.connect(\"prompt\", \"generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0428fbfb-9292-43f8-bf47-f6fdc28c5f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How can I use Cohere with Haystack?\"\n",
    "\n",
    "result = rag.run(\n",
    "    {\n",
    "        \"query_embedder\": {\"text\": question},\n",
    "        \"retriever\": {\"top_k\": 1},\n",
    "        \"prompt\": {\"query\": question, \"language\": \"French\"},\n",
    "    }\n",
    ")\n",
    "\n",
    "print(result[\"generator\"][\"replies\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24636a9-1423-4908-9a47-0e2ac2dce318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57ef485-522d-4892-91ff-1751c348f4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cb5815-e02d-44cb-9916-46a1be3f3af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f64d5-da80-4d7b-a07f-9fe1f90dc4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db692913-6bac-41bc-8bdb-c34bc3c61962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0345290e-5ee9-4ba1-ba21-f74f5dc41a37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
